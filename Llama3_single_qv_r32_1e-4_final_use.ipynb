{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db359a6b-ce2b-496c-882e-1e8afab63483",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.get_chat_template()\n",
    "tokenizer.chat_template\n",
    "# {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
    "# '+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
    "# ' }}{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1259686-364f-4870-8b4c-a36de661dc4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_assisted_decoding',\n",
       " '_auto_class',\n",
       " '_autoset_attn_implementation',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_beam_search',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_and_enable_flash_attn_2',\n",
       " '_check_and_enable_flex_attn',\n",
       " '_check_and_enable_sdpa',\n",
       " '_compiled_call_impl',\n",
       " '_constrained_beam_search',\n",
       " '_contrastive_search',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_copy_lm_head_original_to_resized',\n",
       " '_create_repo',\n",
       " '_dispatch_accelerate_model',\n",
       " '_dola_decoding',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_cache',\n",
       " '_get_candidate_generator',\n",
       " '_get_files_timestamps',\n",
       " '_get_initial_cache_position',\n",
       " '_get_logits_processor',\n",
       " '_get_name',\n",
       " '_get_no_split_modules',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_group_beam_search',\n",
       " '_has_unfinished_sequences',\n",
       " '_hf_peft_config_loaded',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_added_embeddings_weights_with_mean',\n",
       " '_init_added_lm_head_bias_with_mean',\n",
       " '_init_added_lm_head_weights_with_mean',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_is_quantized_training_enabled',\n",
       " '_is_stateful',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_cache_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_generated_length',\n",
       " '_prepare_generation_config',\n",
       " '_prepare_model_inputs',\n",
       " '_prepare_special_tokens',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_sample',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_skip_keys_device_placement',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_supports_cache_class',\n",
       " '_supports_default_dynamic_cache',\n",
       " '_supports_flash_attn_2',\n",
       " '_supports_flex_attn',\n",
       " '_supports_num_logits_to_keep',\n",
       " '_supports_quantized_cache',\n",
       " '_supports_sdpa',\n",
       " '_supports_static_cache',\n",
       " '_temporary_reorder_cache',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_tied_weights_keys',\n",
       " '_tp_plan',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_assistant',\n",
       " '_validate_generated_length',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'add_adapter',\n",
       " 'add_memory_hooks',\n",
       " 'add_model_tags',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'dequantize',\n",
       " 'device',\n",
       " 'disable_adapters',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'enable_adapters',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_adapter_state_dict',\n",
       " 'get_buffer',\n",
       " 'get_compiled_call',\n",
       " 'get_decoder',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'half',\n",
       " 'heal_tokens',\n",
       " 'hf_device_map',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_parallelizable',\n",
       " 'lm_head',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'loss_function',\n",
       " 'main_input_name',\n",
       " 'model',\n",
       " 'model_tags',\n",
       " 'modules',\n",
       " 'mtia',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'reverse_bettertransformer',\n",
       " 'save_pretrained',\n",
       " 'set_adapter',\n",
       " 'set_decoder',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'set_output_embeddings',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'supports_tp_plan',\n",
       " 'tensor_parallel',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_bettertransformer',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'vocab_size',\n",
       " 'warn_if_padding_and_no_attention_mask',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)\n",
    "\n",
    "# LlamaForCausalLM(\n",
    "#   (model): LlamaModel(\n",
    "#     (embed_tokens): Embedding(128256, 4096)\n",
    "#     (layers): ModuleList(\n",
    "#       (0-31): 32 x LlamaDecoderLayer(\n",
    "#         (self_attn): LlamaSdpaAttention(\n",
    "#           (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#           (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#           (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#           (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#           (rotary_emb): LlamaRotaryEmbedding() # 토큰간 상대적 위치 정보 추가\n",
    "#         )\n",
    "#         (mlp): LlamaMLP(\n",
    "#           (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#           (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#           (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#           (act_fn): SiLU()\n",
    "#         )\n",
    "#         (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#       )\n",
    "#     )\n",
    "#     (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#     (rotary_emb): LlamaRotaryEmbedding()\n",
    "#   )\n",
    "#   (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2299652a-08da-4c43-8f62-f2defe29f7db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_call_one',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_pad',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_set_model_specific_special_tokens',\n",
       " '_set_processor_class',\n",
       " '_special_tokens_map',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_upload_modified_files',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'extra_special_tokens',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_chat_template',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480157b8-1763-444a-b859-a4f0512d1860",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665d1e15-ac48-4f39-9cdd-955f81e398a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505bc8b2-1a80-4b25-870b-16994f63fc42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128009,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config\n",
    "\n",
    "# LlamaConfig {\n",
    "#   \"_attn_implementation_autoset\": true,\n",
    "#   \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#   \"architectures\": [\n",
    "#     \"LlamaForCausalLM\"\n",
    "#   ],\n",
    "#   \"attention_bias\": false,\n",
    "#   \"attention_dropout\": 0.0,\n",
    "#   \"bos_token_id\": 128000,\n",
    "#   \"eos_token_id\": 128009,\n",
    "#   \"head_dim\": 128,\n",
    "#   \"hidden_act\": \"silu\",\n",
    "#   \"hidden_size\": 4096,\n",
    "#   \"initializer_range\": 0.02,\n",
    "#   \"intermediate_size\": 14336,\n",
    "#   \"max_position_embeddings\": 8192,\n",
    "#   \"mlp_bias\": false,\n",
    "#   \"model_type\": \"llama\",\n",
    "#   \"num_attention_heads\": 32,\n",
    "#   \"num_hidden_layers\": 32,\n",
    "#   \"num_key_value_heads\": 8,\n",
    "#   \"pretraining_tp\": 1,\n",
    "#   \"rms_norm_eps\": 1e-05,\n",
    "#   \"rope_scaling\": null,\n",
    "#   \"rope_theta\": 500000.0,\n",
    "#   \"tie_word_embeddings\": false,\n",
    "#   \"torch_dtype\": \"bfloat16\",\n",
    "#   \"transformers_version\": \"4.47.1\",\n",
    "#   \"use_cache\": false,\n",
    "#   \"vocab_size\": 128256\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96f7b56-c1a7-4a5a-bcfc-987a5c8b2c7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "\n",
    "### model\n",
    "# PeftModelForCausalLM(\n",
    "#   (base_model): LoraModel(\n",
    "#     (model): LlamaForCausalLM(\n",
    "#       (model): LlamaModel(\n",
    "#         (embed_tokens): Embedding(128256, 4096)\n",
    "#         (layers): ModuleList(\n",
    "#           (0-31): 32 x LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#         )\n",
    "#         (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (rotary_emb): LlamaRotaryEmbedding()\n",
    "#       )\n",
    "#       (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "#     )\n",
    "#   )\n",
    "# )\n",
    "\n",
    "### q, k, v, mlp\n",
    "# PeftModelForCausalLM(\n",
    "#   (base_model): LoraModel(\n",
    "#     (model): LlamaForCausalLM(\n",
    "#       (model): LlamaModel(\n",
    "#         (embed_tokens): Embedding(128256, 4096)\n",
    "#         (layers): ModuleList(\n",
    "#           (0): LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (up_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (down_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=14336, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#           (1-31): 31 x LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (up_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (down_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=14336, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#         )\n",
    "#         (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (rotary_emb): LlamaRotaryEmbedding()\n",
    "#       )\n",
    "#       (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "#     )\n",
    "#   )\n",
    "# )\n",
    "\n",
    "### modle.train()\n",
    "# PeftModelForCausalLM(\n",
    "#   (base_model): LoraModel(\n",
    "#     (model): LlamaForCausalLM(\n",
    "#       (model): LlamaModel(\n",
    "#         (embed_tokens): Embedding(128256, 4096)\n",
    "#         (layers): ModuleList(\n",
    "#           (0-31): 32 x LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#         )\n",
    "#         (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (rotary_emb): LlamaRotaryEmbedding()\n",
    "#       )\n",
    "#       (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "#     )\n",
    "#   )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e322f8-c271-4354-aaa9-5d2d222eb32d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de6cf2c-ec4f-4a28-90fc-13c7c6f9990a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_new_adapter_config',\n",
       " '_compiled_call_impl',\n",
       " '_cpt_forward',\n",
       " '_create_repo',\n",
       " '_enable_peft_forward_hooks',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_base_model_class',\n",
       " '_get_files_timestamps',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_is_prompt_learning',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_peft_config',\n",
       " '_prepare_model_for_gradient_checkpointing',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_setup_prompt_encoder',\n",
       " '_slow_forward',\n",
       " '_split_kwargs',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_update_offload',\n",
       " '_upload_modified_files',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'active_peft_config',\n",
       " 'add_adapter',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prepare_inputs_for_generation',\n",
       " 'base_model_torch_dtype',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'create_or_update_model_card',\n",
       " 'cuda',\n",
       " 'disable_adapter',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'get_base_model',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_layer_status',\n",
       " 'get_model_status',\n",
       " 'get_nb_trainable_parameters',\n",
       " 'get_parameter',\n",
       " 'get_prompt',\n",
       " 'get_prompt_embedding_to_save',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'modules_to_save',\n",
       " 'mtia',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'peft_config',\n",
       " 'peft_type',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'print_trainable_parameters',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'save_pretrained',\n",
       " 'set_adapter',\n",
       " 'set_additional_trainable_modules',\n",
       " 'set_extra_state',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'special_peft_forward_args',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9de386-d404-493e-a6e0-0f7e945de562",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenized_train_datasets \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m :\n\u001b[1;32m      3\u001b[0m     tokenized_train_datasets\u001b[38;5;241m.\u001b[39mappend(tokenizer(train, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m tokenized_valid_datasets \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_train_datasets = []\n",
    "for train in train_dataset :\n",
    "    tokenized_train_datasets.append(tokenizer(train, max_length=1024, padding=\"max_length\"))\n",
    "\n",
    "tokenized_valid_datasets = []\n",
    "for valid in val_dataset :\n",
    "    tokenized_valid_datasets.append(tokenizer(valid, max_length=1024, padding=\"max_length\"))\n",
    "\n",
    "# tokenized_valid_datasets = tokenizer(val_dataset, max_length=2048, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e6760-10a1-4e2a-bb61-d6929637c3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"datasets\" \"torch\" \"torchvision\" \"torchaudio\" \"transformers\" \"accelerate\" \"trl\" --quiet\n",
    "!pip install bitsandbytes --quiet\n",
    "!pip install huggingface_hub --quiet\n",
    "!pip install flash-attn --no-build-isolation --quiet\n",
    "!pip install peft --quiet\n",
    "!pip install tf-keras --quiet\n",
    "# !pip install opacus --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199c2082-329f-4643-844d-80b5cbe3389c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGD\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainerCallback, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, LoraModel\n",
    "from trl import SFTTrainer, setup_chat_format, SFTConfig\n",
    "# from opacus import PrivacyEngine, GradSampleModule\n",
    "from datasets import Dataset, load_dataset\n",
    "from accelerate import Accelerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9ddf3c-4e33-4b90-b1a0-99b35963f4db",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JSON 데이터 로드 함수\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    formatted_data = []\n",
    "    for item in dataset:\n",
    "        formatted_data.append({\n",
    "            \"input_text\": item[\"input_text\"],\n",
    "            \"response_text\": item[\"response_text\"]\n",
    "        })\n",
    "    return formatted_data\n",
    "\n",
    "def format_instruction(dataset):\n",
    "    # 포맷팅된 데이터 생성\n",
    "    # Definition 부분\n",
    "    definition = 'Given a patient’s sequential ICD diagnosis history, where earlier diagnoses appear first and later diagnoses follow, generate a structured list of prescription drugs with administration routes. Ensure that the output considers the progression of diagnoses and adjusts treatments accordingly. The output format should be as follows: [Drug Name - Route, Drug Name - Route, …]. Example: A 39-year-old female patient with a blood pressure of 120/70, height of 160.0 cm, weight of 77.6 kg, and ICD diagnosis history of [Diverticulitis of colon (without mention of hemorrhage), Abscess of intestine, Depressive disorder, not elsewhere classified] should be output as: Prescription drug (example: drug-route): [Morphine Sulfate - IV, Acetaminophen - PO, HYDROmorphone (Dilaudid) - IV, Oxycodone-Acetaminophen - PO, Ciprofloxacin IV - IV, Fluoxetine - PO, Heparin - SC].'\n",
    "    chat_input = [\n",
    "        {\"role\": \"system\", \"content\": definition},\n",
    "        {\"role\": \"user\", \"content\": dataset['text'][\"input_text\"]},\n",
    "        {\"role\": \"assistant\", \"content\": dataset['text'][\"response_text\"]}\n",
    "    ]\n",
    "    formatted_sample = tokenizer.apply_chat_template(chat_input, tokenize=False, max_length = 2048)\n",
    "    return formatted_sample\n",
    "\n",
    "# 데이터셋 나누기\n",
    "dataset_path = \"/tf/notebooks/NFS_Dataset/Federated_Inference/MIMIC_Hospital_train.json\"\n",
    "train_data = load_data(dataset_path)\n",
    "\n",
    "# 리스트로된 데이터셋 Dataset 자료형으로 변환\n",
    "if isinstance(train_data, list):\n",
    "    train_data = Dataset.from_dict({\"text\": train_data})\n",
    "# if isinstance(val_data, list):\n",
    "#     val_data = Dataset.from_dict({\"text\": val_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5c0d00-8b01-4ec8-866f-21accaa782ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40265"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3385e35-cf0b-4160-951d-34a36bf96ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e6f41319e84b87aaf3cb952cc732f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"  # 사용할 모델 ID\n",
    "use_flash_attention = True  # Flash Attention 사용 여부 설정\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_cache=False,  # 캐시 사용 안 함, Flash_Attention을 사용하게 된다면 use_cache는 사용하지 못함, 따라서 use_cache는 추론시에만 사용\n",
    "        attn_implementation=\"flash_attention_2\",  # 수정\n",
    "        device_map='cuda',\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)  # 토크나이저 불러오기\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"  # 패딩 토큰을 EOS 토큰으로 설정\n",
    "tokenizer.padding_side = \"right\"  # 패딩을 오른쪽에 추가\n",
    "\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe7d7a7-e0fd-4840-98d3-a36192171f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    init_lora_weights = 'gaussian', #  LoRA 레이어의 초기 가중치를 Gaussian 분포에서 샘플링하여 초기화\n",
    "    r=32,  # LoRA 차원 수\n",
    "    lora_alpha=16,  # LoRA 스케일링 파라미터\n",
    "    lora_dropout=0.1,  # LoRA 드롭아웃 비율\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # LoRA를 적용할 모듈 / proj라고 붙은 이름들에 전부 붙일 수 있다.\n",
    "    bias=\"none\",  # 바이어스 처리 방법\n",
    "    task_type=\"CAUSAL_LM\"  # 작업 유형 (언어 모델링)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3 # 1e-4로 Loss감소율이 너무 낮아서 바꿈 (Loss 1.3 -> 1.28)\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=\"./checkpoint_single_Llama3-1_r32_a16_l3e-3_b16_wu3\", # 수정 필요할수도\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    # per_device_eval_batch_size=4,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_strategy = \"epoch\",\n",
    "    # eval_strategy = \"steps\",\n",
    "    # save_steps = 100,\n",
    "    logging_steps = 10,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    tf32=True,\n",
    "    max_seq_length=2048,\n",
    "    packing=True,\n",
    "    learning_rate = learning_rate,\n",
    "    warmup_ratio = 0.3\n",
    ")\n",
    "\n",
    "## BF16과 TF32를 동시에 설정하면?\n",
    "# 우선순위와 동작 방식\n",
    "# \t1.\tBF16 적용:\n",
    "# \t•\tbf16=True로 설정하면 **모델의 전체 데이터 유형(dtype)**이 torch.bfloat16으로 설정됩니다.\n",
    "# \t•\t모델의 파라미터와 연산이 기본적으로 BF16으로 처리됩니다.\n",
    "# \t2.\tTF32 적용:\n",
    "# \t•\ttf32=True는 GPU의 특정 연산(GEMM, 즉 행렬 곱셈 연산)에만 적용되며, BF16으로 설정된 연산에도 영향을 미칠 수 있습니다.\n",
    "# \t•\tBF16이 이미 설정된 경우에도, TF32는 행렬 곱셈 연산에서 사용될 수 있습니다.\n",
    "# 결론적으로, 모델의 파라미터가 BF16로 동작하면서, GPU의 행렬 곱셈 연산은 TF32 설정에 따라 최적화됩니다.\n",
    "\n",
    "# Flash Attention을 사용하는 경우 레이어 업캐스팅\n",
    "if use_flash_attention:\n",
    "    from deep_learning_pytorch_huggingface.training.utils.llama_patch import upcast_layer_for_flash_attention\n",
    "    torch_dtype = torch.bfloat16 if args.bf16 else torch.float16 if args.fp16 else torch.float32  # 데이터 타입 설정\n",
    "    model = upcast_layer_for_flash_attention(model, torch_dtype)  # Flash Attention을 위한 업캐스팅 적용\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# # FA-LoRA 설정\n",
    "# # lora_A 파라미터 동결, 나머지 파라미터는 미세 조정 허용\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'lora_A' in name:  # lora_A 파라미터인 경우\n",
    "#         param.requires_grad = False  # 이 파라미터 동결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f33a654-98f2-496d-877a-fb99fc3b2c57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.0.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.1.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.2.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.3.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.4.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.5.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.6.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.7.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.8.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.9.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.10.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.11.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.12.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.13.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.14.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.15.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.16.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.17.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.18.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.19.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.20.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.21.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.22.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.23.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.24.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.25.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.26.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.27.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.28.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.29.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.30.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.31.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: Trainable\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.norm.weight: Frozen\n",
      "base_model.model.lm_head.weight: Frozen\n"
     ]
    }
   ],
   "source": [
    "model.enable_input_require_grads()\n",
    "# 레이어 동결 상태 출력\n",
    "def print_layer_freeze_status(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        status = \"Frozen\" if not param.requires_grad else \"Trainable\"\n",
    "        print(f\"{name}: {status}\")\n",
    "\n",
    "# 동결 상태 확인\n",
    "print_layer_freeze_status(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccd4e78-1c0a-45d2-9e33-232c2cdb4df6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from opacus.accountants import RDPAccountant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3d06d1-21bf-4850-ae95-917fdf69d508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5869ea1e7b86400993dacf73ab14274e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/40265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443853bf44da4022b160e3c7cf01dd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/40265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b418c775d948069ebec13c9fe10022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/40265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1763d9e223f45f5973276f6b63ed889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/40265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1a556b9df34c33b21e592e19960c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Packing train dataset:   0%|          | 0/40265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(model.parameters(), lr=args.learning_rate)\n",
    "# SFTTrainer가 리스트로 된 데이터셋을 원래 받았지만 현재는 Dataset자료형으로 변환해야 한다.\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  # 모델\n",
    "    train_dataset=train_data,  # 훈련 데이터셋\n",
    "    # eval_dataset=val_data,  # 검증 데이터셋 추가\n",
    "    peft_config=peft_config,  # LoRA 설정\n",
    "    # tokenizer=tokenizer,  # 토크나이저\n",
    "    formatting_func = format_instruction,\n",
    "    args=args,  # 훈련 인자\n",
    "    optimizers = (optimizer, None) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c71aa4-01c6-4c86-917c-478462a5ee70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5242880 || all params: 8043892736 || trainable%: 0.06517839275175537\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "    \n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c2c8e8-3fc3-4b58-ae0f-ee778fa57db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321002a7-5868-41fd-91cb-e429ce0aa30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='4075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/4075 00:16 < 19:06:54, 0.06 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# Train\n",
    "trainer.train()\n",
    "# Save model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f97a5f-8a1a-483f-a582-e8d97cb7bf32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e32162-a389-48ea-9934-f2e82bd4e9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids'],\n",
       "    num_rows: 15598\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d21d99-900d-414a-bfd1-a931193e52a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2025 04:06:34:WARNING:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed Type: DistributedType.NO\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator, PartialState\n",
    "\n",
    "# 강제 리셋 후 Accelerator 다시 생성\n",
    "PartialState()._reset_state()\n",
    "accelerator = Accelerator()\n",
    "\n",
    "print(f\"Distributed Type: {accelerator.distributed_type}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed481d5c-92c8-4485-b789-ad2a08975b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b552fe-d8e6-4d52-af4b-c41c9b7ed3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03d7ec781d414966a4e8bce197aef29d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "073eed245ceb4dc190764722fdc55f2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0907d38e43da456d9ff0b8188ca28a85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0abd6aaef4074ac2a34cdcd8ecfe4671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0bdfb9665edf4121b5c9146b7eca2923": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0d13e9465e9343ebb92f54a61ec0dd36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0d9af317a84847b39446cd17f9b26362": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0e63ff35ba1844d9ab81fe39f9811227": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1c300b4dc16046439749104b2d323b1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ab2c46a47e744d8cac96815e8fa2d568",
       "style": "IPY_MODEL_5ac19db021754dc9bf0cea84a55ca023",
       "value": "Generating train split: "
      }
     },
     "235ccf024865480ebe0944a7d23f38ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fdc016cc19a94caf88f790af174936f1",
       "style": "IPY_MODEL_fdc392b00f864e1dba03e817f75fd262",
       "value": " 8314/0 [00:07&lt;00:00, 1224.06 examples/s]"
      }
     },
     "2696fab4680d44d996c6e1a19a86c958": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "286ba6ceb386439f89d7d6fd7181115b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5d0da7f7120245bd8cf7d9a9c62fe535",
       "style": "IPY_MODEL_5432c4e15c2b42ac8cf5af3e26fe24f0",
       "value": " 4/4 [00:08&lt;00:00,  1.76s/it]"
      }
     },
     "29ff27b53c6142e9a86a236b0c7cf577": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2cbd91e59e4444049d10841672f978d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3088096846564f368153eb7326b4e0d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c4a58f766a924542b7cc5ed43d0858c9",
       "style": "IPY_MODEL_56660e55a46e4b0fac9be368f6baca72",
       "value": "Generating train split: "
      }
     },
     "308b9aaa8a2241cc9790cca792f45359": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3288f7c5c1d44601ab83ae94846b5256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e8c6cd6136af444ab996aa13be4d8a82",
       "max": 1,
       "style": "IPY_MODEL_aa814a9564bc406a868cbe2837fd6b93",
       "value": 1
      }
     },
     "3356534312e24e76acc3567911cf197c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36f3707b8f4945439a818d3e7a6c2e56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3d284239fd334df5beab82da4a8da7de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "416b41ea5a9c4d4ca8c7d55eaf664315": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_df17ea71178f4842910cab9d6c59b164",
        "IPY_MODEL_cc9be6f70c3643fea9cf0e090879040e",
        "IPY_MODEL_421960ad460a4a48b1179f948002cbe7"
       ],
       "layout": "IPY_MODEL_72a9f20a8435494aa9c198ea9dff8034"
      }
     },
     "421960ad460a4a48b1179f948002cbe7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0bdfb9665edf4121b5c9146b7eca2923",
       "style": "IPY_MODEL_2696fab4680d44d996c6e1a19a86c958",
       "value": " 9773/0 [00:09&lt;00:00, 1408.11 examples/s]"
      }
     },
     "45c0d3d05eb24c7c8b0e3efba8910de0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "46510af32f5b42b083ec79795b40cd23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "479d8cbcf5ea485fb7c861e9cd54c295": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_29ff27b53c6142e9a86a236b0c7cf577",
       "style": "IPY_MODEL_2cbd91e59e4444049d10841672f978d3",
       "value": "Generating train split: "
      }
     },
     "47b5d3f3d4d74c6d8ac59313332047f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_308b9aaa8a2241cc9790cca792f45359",
       "style": "IPY_MODEL_f87a156ab3e7456aaae3a80cdd7f7bec",
       "value": " 1457/0 [00:01&lt;00:00, 1081.44 examples/s]"
      }
     },
     "4957bb5a9eb142c78b4a39b6d23cf1ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "4a70c49bb1ba4ae78f2d561262b087df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b3eff105192407ab100bca6f7e061bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_03d7ec781d414966a4e8bce197aef29d",
       "style": "IPY_MODEL_0907d38e43da456d9ff0b8188ca28a85",
       "value": " 0/0 [00:00&lt;?, ? examples/s]"
      }
     },
     "4dc9f25963ac404fb6c6742d200393d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5432c4e15c2b42ac8cf5af3e26fe24f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "56660e55a46e4b0fac9be368f6baca72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a8c5f8842414720b83f39e8cfb4ca1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0d9af317a84847b39446cd17f9b26362",
       "max": 4,
       "style": "IPY_MODEL_ff7ea10e8ba744e996d31e11f6babe93",
       "value": 4
      }
     },
     "5ac19db021754dc9bf0cea84a55ca023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d0da7f7120245bd8cf7d9a9c62fe535": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e9c49fb26b545c1b8655c346cb7ea2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "625bd95fa39e40a080c6a99eca89aa23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6f8c6f3fc5fc49a197cbca787bd122bb",
        "IPY_MODEL_7937453627294a7f89825841c6fc9e25",
        "IPY_MODEL_47b5d3f3d4d74c6d8ac59313332047f3"
       ],
       "layout": "IPY_MODEL_073eed245ceb4dc190764722fdc55f2e"
      }
     },
     "6772ebbe4e854afd9299d89b16ca9029": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_36f3707b8f4945439a818d3e7a6c2e56",
       "style": "IPY_MODEL_0e63ff35ba1844d9ab81fe39f9811227",
       "value": " 9773/0 [00:09&lt;00:00, 1233.85 examples/s]"
      }
     },
     "6b5f7ae8a4434c0395fa1104840e4a17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6f8c6f3fc5fc49a197cbca787bd122bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ef5e5a532a394dd0aa87b0bb246b8c80",
       "style": "IPY_MODEL_4dc9f25963ac404fb6c6742d200393d0",
       "value": "Generating train split: "
      }
     },
     "72a9f20a8435494aa9c198ea9dff8034": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "75709efbf72142d5b2133b175a2a7fb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7937453627294a7f89825841c6fc9e25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4957bb5a9eb142c78b4a39b6d23cf1ea",
       "max": 1,
       "style": "IPY_MODEL_ba9482671df044199cfba003f07db92a",
       "value": 1
      }
     },
     "79e5c8868bb140fab28659d94b65829e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "84e2f6eb6bf54d068a84f9ce398bb6d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_479d8cbcf5ea485fb7c861e9cd54c295",
        "IPY_MODEL_ef4ee7f808ea4315a7e7d27f8c39a49b",
        "IPY_MODEL_4b3eff105192407ab100bca6f7e061bd"
       ],
       "layout": "IPY_MODEL_b61e2236536144328040de9d4c0528ef"
      }
     },
     "851a204b2cfd4e06b243b8e63cbeb634": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f4ac1df42b074189bfe0890a9824cc40",
        "IPY_MODEL_5a8c5f8842414720b83f39e8cfb4ca1f",
        "IPY_MODEL_286ba6ceb386439f89d7d6fd7181115b"
       ],
       "layout": "IPY_MODEL_db91f88a69084e7e8b0457c69cf386e6"
      }
     },
     "8d44dd3f0e2c4214b5678d41a788b569": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_cf369480428e4ce29b11d28c52e7b3ac",
       "max": 1,
       "style": "IPY_MODEL_eea8a1a60746487b9a4ab6c571771ea1",
       "value": 1
      }
     },
     "913f557c6c4f4c95835967151f5f6d18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "94a1406937ee48f6b00c394a8db8022b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "95395ccf34dc4f7681c4c6780730ccff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3088096846564f368153eb7326b4e0d1",
        "IPY_MODEL_f91106ecc2c1419385b95e5bc3035eb6",
        "IPY_MODEL_e2f509f2a4434b05869ff51482185c9a"
       ],
       "layout": "IPY_MODEL_6b5f7ae8a4434c0395fa1104840e4a17"
      }
     },
     "9eded75f89544520be8c8436b2c5506e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9fda8c11cfca435e970dd2208ff0d38a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "a296162334e648b6a09885e51cdac152": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a71a321b41094b03b2c39ab5f6b0237d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a296162334e648b6a09885e51cdac152",
       "style": "IPY_MODEL_913f557c6c4f4c95835967151f5f6d18",
       "value": "Generating train split: "
      }
     },
     "a9c15f23a95b436d9976ace1957b463f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa814a9564bc406a868cbe2837fd6b93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ab2c46a47e744d8cac96815e8fa2d568": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ac6f25d6ba164230a49d04d39c47e2d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1c300b4dc16046439749104b2d323b1e",
        "IPY_MODEL_ed24520274414986843b142ff9f1e0b8",
        "IPY_MODEL_b3712fcff817417ca00433b04641d074"
       ],
       "layout": "IPY_MODEL_4a70c49bb1ba4ae78f2d561262b087df"
      }
     },
     "ac89667aff7a4d9d9d1c4860119ad48d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0abd6aaef4074ac2a34cdcd8ecfe4671",
       "style": "IPY_MODEL_46510af32f5b42b083ec79795b40cd23",
       "value": "Generating train split: "
      }
     },
     "af7db4bb4b194e688b12d152fd14b41b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b0f9cf20f5654311bfccd89d3c046fc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b3712fcff817417ca00433b04641d074": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_75709efbf72142d5b2133b175a2a7fb3",
       "style": "IPY_MODEL_a9c15f23a95b436d9976ace1957b463f",
       "value": " 1457/0 [00:01&lt;00:00, 1120.62 examples/s]"
      }
     },
     "b61e2236536144328040de9d4c0528ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b69d5227124f415588a7919ca1c968f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "ba9482671df044199cfba003f07db92a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c107bb81f62c4aabb1c677c9930bb7c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a71a321b41094b03b2c39ab5f6b0237d",
        "IPY_MODEL_8d44dd3f0e2c4214b5678d41a788b569",
        "IPY_MODEL_6772ebbe4e854afd9299d89b16ca9029"
       ],
       "layout": "IPY_MODEL_9eded75f89544520be8c8436b2c5506e"
      }
     },
     "c4a58f766a924542b7cc5ed43d0858c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cbf0aabb97ce4e2e87ab420174dfc82d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cc9be6f70c3643fea9cf0e090879040e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9fda8c11cfca435e970dd2208ff0d38a",
       "max": 1,
       "style": "IPY_MODEL_d98ae21d06de4cf3beddf85cd00145f8",
       "value": 1
      }
     },
     "cf369480428e4ce29b11d28c52e7b3ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "d2af533cb2db40caaf940ac1edf3f981": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ac89667aff7a4d9d9d1c4860119ad48d",
        "IPY_MODEL_3288f7c5c1d44601ab83ae94846b5256",
        "IPY_MODEL_235ccf024865480ebe0944a7d23f38ca"
       ],
       "layout": "IPY_MODEL_79e5c8868bb140fab28659d94b65829e"
      }
     },
     "d98ae21d06de4cf3beddf85cd00145f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "db91f88a69084e7e8b0457c69cf386e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "df17ea71178f4842910cab9d6c59b164": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_94a1406937ee48f6b00c394a8db8022b",
       "style": "IPY_MODEL_45c0d3d05eb24c7c8b0e3efba8910de0",
       "value": "Generating train split: "
      }
     },
     "e1519badfb7949959e7d6eb9fb7eebeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "e2f509f2a4434b05869ff51482185c9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cbf0aabb97ce4e2e87ab420174dfc82d",
       "style": "IPY_MODEL_3d284239fd334df5beab82da4a8da7de",
       "value": " 8314/0 [00:08&lt;00:00, 1173.03 examples/s]"
      }
     },
     "e8c6cd6136af444ab996aa13be4d8a82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "ed24520274414986843b142ff9f1e0b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b69d5227124f415588a7919ca1c968f4",
       "max": 1,
       "style": "IPY_MODEL_af7db4bb4b194e688b12d152fd14b41b",
       "value": 1
      }
     },
     "eea8a1a60746487b9a4ab6c571771ea1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ef4ee7f808ea4315a7e7d27f8c39a49b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_5e9c49fb26b545c1b8655c346cb7ea2f",
       "max": 1,
       "style": "IPY_MODEL_0d13e9465e9343ebb92f54a61ec0dd36"
      }
     },
     "ef5e5a532a394dd0aa87b0bb246b8c80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4ac1df42b074189bfe0890a9824cc40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3356534312e24e76acc3567911cf197c",
       "style": "IPY_MODEL_ff21973bf04c42a98242fdaac874ee3d",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "f87a156ab3e7456aaae3a80cdd7f7bec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f91106ecc2c1419385b95e5bc3035eb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e1519badfb7949959e7d6eb9fb7eebeb",
       "max": 1,
       "style": "IPY_MODEL_b0f9cf20f5654311bfccd89d3c046fc7",
       "value": 1
      }
     },
     "fdc016cc19a94caf88f790af174936f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fdc392b00f864e1dba03e817f75fd262": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ff21973bf04c42a98242fdaac874ee3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ff7ea10e8ba744e996d31e11f6babe93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
