{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db359a6b-ce2b-496c-882e-1e8afab63483",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.get_chat_template()\n",
    "tokenizer.chat_template\n",
    "# {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
    "# '+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
    "# ' }}{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1259686-364f-4870-8b4c-a36de661dc4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_assisted_decoding',\n",
       " '_auto_class',\n",
       " '_autoset_attn_implementation',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_beam_search',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_and_enable_flash_attn_2',\n",
       " '_check_and_enable_flex_attn',\n",
       " '_check_and_enable_sdpa',\n",
       " '_compiled_call_impl',\n",
       " '_constrained_beam_search',\n",
       " '_contrastive_search',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_copy_lm_head_original_to_resized',\n",
       " '_create_repo',\n",
       " '_dispatch_accelerate_model',\n",
       " '_dola_decoding',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_cache',\n",
       " '_get_candidate_generator',\n",
       " '_get_files_timestamps',\n",
       " '_get_initial_cache_position',\n",
       " '_get_logits_processor',\n",
       " '_get_name',\n",
       " '_get_no_split_modules',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_group_beam_search',\n",
       " '_has_unfinished_sequences',\n",
       " '_hf_peft_config_loaded',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_added_embeddings_weights_with_mean',\n",
       " '_init_added_lm_head_bias_with_mean',\n",
       " '_init_added_lm_head_weights_with_mean',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_is_quantized_training_enabled',\n",
       " '_is_stateful',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_cache_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_generated_length',\n",
       " '_prepare_generation_config',\n",
       " '_prepare_model_inputs',\n",
       " '_prepare_special_tokens',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_sample',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_skip_keys_device_placement',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_supports_cache_class',\n",
       " '_supports_default_dynamic_cache',\n",
       " '_supports_flash_attn_2',\n",
       " '_supports_flex_attn',\n",
       " '_supports_num_logits_to_keep',\n",
       " '_supports_quantized_cache',\n",
       " '_supports_sdpa',\n",
       " '_supports_static_cache',\n",
       " '_temporary_reorder_cache',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_tied_weights_keys',\n",
       " '_tp_plan',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_assistant',\n",
       " '_validate_generated_length',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'add_adapter',\n",
       " 'add_memory_hooks',\n",
       " 'add_model_tags',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'dequantize',\n",
       " 'device',\n",
       " 'disable_adapters',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'enable_adapters',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_adapter_state_dict',\n",
       " 'get_buffer',\n",
       " 'get_compiled_call',\n",
       " 'get_decoder',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'half',\n",
       " 'heal_tokens',\n",
       " 'hf_device_map',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_parallelizable',\n",
       " 'lm_head',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'loss_function',\n",
       " 'main_input_name',\n",
       " 'model',\n",
       " 'model_tags',\n",
       " 'modules',\n",
       " 'mtia',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'reverse_bettertransformer',\n",
       " 'save_pretrained',\n",
       " 'set_adapter',\n",
       " 'set_decoder',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'set_output_embeddings',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'supports_tp_plan',\n",
       " 'tensor_parallel',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_bettertransformer',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'vocab_size',\n",
       " 'warn_if_padding_and_no_attention_mask',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)\n",
    "\n",
    "# LlamaForCausalLM(\n",
    "#   (model): LlamaModel(\n",
    "#     (embed_tokens): Embedding(128256, 4096)\n",
    "#     (layers): ModuleList(\n",
    "#       (0-31): 32 x LlamaDecoderLayer(\n",
    "#         (self_attn): LlamaSdpaAttention(\n",
    "#           (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#           (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#           (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#           (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#           (rotary_emb): LlamaRotaryEmbedding() # 토큰간 상대적 위치 정보 추가\n",
    "#         )\n",
    "#         (mlp): LlamaMLP(\n",
    "#           (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#           (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#           (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#           (act_fn): SiLU()\n",
    "#         )\n",
    "#         (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#       )\n",
    "#     )\n",
    "#     (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#     (rotary_emb): LlamaRotaryEmbedding()\n",
    "#   )\n",
    "#   (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2299652a-08da-4c43-8f62-f2defe29f7db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_call_one',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_pad',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_set_model_specific_special_tokens',\n",
       " '_set_processor_class',\n",
       " '_special_tokens_map',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_upload_modified_files',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'extra_special_tokens',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_chat_template',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480157b8-1763-444a-b859-a4f0512d1860",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665d1e15-ac48-4f39-9cdd-955f81e398a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505bc8b2-1a80-4b25-870b-16994f63fc42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128009,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config\n",
    "\n",
    "# LlamaConfig {\n",
    "#   \"_attn_implementation_autoset\": true,\n",
    "#   \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#   \"architectures\": [\n",
    "#     \"LlamaForCausalLM\"\n",
    "#   ],\n",
    "#   \"attention_bias\": false,\n",
    "#   \"attention_dropout\": 0.0,\n",
    "#   \"bos_token_id\": 128000,\n",
    "#   \"eos_token_id\": 128009,\n",
    "#   \"head_dim\": 128,\n",
    "#   \"hidden_act\": \"silu\",\n",
    "#   \"hidden_size\": 4096,\n",
    "#   \"initializer_range\": 0.02,\n",
    "#   \"intermediate_size\": 14336,\n",
    "#   \"max_position_embeddings\": 8192,\n",
    "#   \"mlp_bias\": false,\n",
    "#   \"model_type\": \"llama\",\n",
    "#   \"num_attention_heads\": 32,\n",
    "#   \"num_hidden_layers\": 32,\n",
    "#   \"num_key_value_heads\": 8,\n",
    "#   \"pretraining_tp\": 1,\n",
    "#   \"rms_norm_eps\": 1e-05,\n",
    "#   \"rope_scaling\": null,\n",
    "#   \"rope_theta\": 500000.0,\n",
    "#   \"tie_word_embeddings\": false,\n",
    "#   \"torch_dtype\": \"bfloat16\",\n",
    "#   \"transformers_version\": \"4.47.1\",\n",
    "#   \"use_cache\": false,\n",
    "#   \"vocab_size\": 128256\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96f7b56-c1a7-4a5a-bcfc-987a5c8b2c7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "\n",
    "### model\n",
    "# PeftModelForCausalLM(\n",
    "#   (base_model): LoraModel(\n",
    "#     (model): LlamaForCausalLM(\n",
    "#       (model): LlamaModel(\n",
    "#         (embed_tokens): Embedding(128256, 4096)\n",
    "#         (layers): ModuleList(\n",
    "#           (0-31): 32 x LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#         )\n",
    "#         (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (rotary_emb): LlamaRotaryEmbedding()\n",
    "#       )\n",
    "#       (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "#     )\n",
    "#   )\n",
    "# )\n",
    "\n",
    "### q, k, v, mlp\n",
    "# PeftModelForCausalLM(\n",
    "#   (base_model): LoraModel(\n",
    "#     (model): LlamaForCausalLM(\n",
    "#       (model): LlamaModel(\n",
    "#         (embed_tokens): Embedding(128256, 4096)\n",
    "#         (layers): ModuleList(\n",
    "#           (0): LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (up_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (down_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=14336, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#           (1-31): 31 x LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (up_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=14336, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (down_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=14336, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#         )\n",
    "#         (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (rotary_emb): LlamaRotaryEmbedding()\n",
    "#       )\n",
    "#       (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "#     )\n",
    "#   )\n",
    "# )\n",
    "\n",
    "### modle.train()\n",
    "# PeftModelForCausalLM(\n",
    "#   (base_model): LoraModel(\n",
    "#     (model): LlamaForCausalLM(\n",
    "#       (model): LlamaModel(\n",
    "#         (embed_tokens): Embedding(128256, 4096)\n",
    "#         (layers): ModuleList(\n",
    "#           (0-31): 32 x LlamaDecoderLayer(\n",
    "#             (self_attn): LlamaSdpaAttention(\n",
    "#               (q_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=4096, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#               (v_proj): lora.Linear(\n",
    "#                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
    "#                 (lora_dropout): ModuleDict(\n",
    "#                   (default): Dropout(p=0.1, inplace=False)\n",
    "#                 )\n",
    "#                 (lora_A): ModuleDict(\n",
    "#                   (default): Linear(in_features=4096, out_features=16, bias=False)\n",
    "#                 )\n",
    "#                 (lora_B): ModuleDict(\n",
    "#                   (default): Linear(in_features=16, out_features=1024, bias=False)\n",
    "#                 )\n",
    "#                 (lora_embedding_A): ParameterDict()\n",
    "#                 (lora_embedding_B): ParameterDict()\n",
    "#                 (lora_magnitude_vector): ModuleDict()\n",
    "#               )\n",
    "#               (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "#               (rotary_emb): LlamaRotaryEmbedding()\n",
    "#             )\n",
    "#             (mlp): LlamaMLP(\n",
    "#               (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
    "#               (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
    "#               (act_fn): SiLU()\n",
    "#             )\n",
    "#             (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#             (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#           )\n",
    "#         )\n",
    "#         (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
    "#         (rotary_emb): LlamaRotaryEmbedding()\n",
    "#       )\n",
    "#       (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
    "#     )\n",
    "#   )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e322f8-c271-4354-aaa9-5d2d222eb32d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de6cf2c-ec4f-4a28-90fc-13c7c6f9990a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_new_adapter_config',\n",
       " '_compiled_call_impl',\n",
       " '_cpt_forward',\n",
       " '_create_repo',\n",
       " '_enable_peft_forward_hooks',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_base_model_class',\n",
       " '_get_files_timestamps',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_is_prompt_learning',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_peft_config',\n",
       " '_prepare_model_for_gradient_checkpointing',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_setup_prompt_encoder',\n",
       " '_slow_forward',\n",
       " '_split_kwargs',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_update_offload',\n",
       " '_upload_modified_files',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'active_peft_config',\n",
       " 'add_adapter',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prepare_inputs_for_generation',\n",
       " 'base_model_torch_dtype',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'create_or_update_model_card',\n",
       " 'cuda',\n",
       " 'disable_adapter',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'get_base_model',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_layer_status',\n",
       " 'get_model_status',\n",
       " 'get_nb_trainable_parameters',\n",
       " 'get_parameter',\n",
       " 'get_prompt',\n",
       " 'get_prompt_embedding_to_save',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'modules_to_save',\n",
       " 'mtia',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'peft_config',\n",
       " 'peft_type',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'print_trainable_parameters',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'save_pretrained',\n",
       " 'set_adapter',\n",
       " 'set_additional_trainable_modules',\n",
       " 'set_extra_state',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'special_peft_forward_args',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9de386-d404-493e-a6e0-0f7e945de562",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenized_train_datasets \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m :\n\u001b[1;32m      3\u001b[0m     tokenized_train_datasets\u001b[38;5;241m.\u001b[39mappend(tokenizer(train, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m tokenized_valid_datasets \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_train_datasets = []\n",
    "for train in train_dataset :\n",
    "    tokenized_train_datasets.append(tokenizer(train, max_length=1024, padding=\"max_length\"))\n",
    "\n",
    "tokenized_valid_datasets = []\n",
    "for valid in val_dataset :\n",
    "    tokenized_valid_datasets.append(tokenizer(valid, max_length=1024, padding=\"max_length\"))\n",
    "\n",
    "# tokenized_valid_datasets = tokenizer(val_dataset, max_length=2048, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907e6760-10a1-4e2a-bb61-d6929637c3cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --queit\n"
     ]
    }
   ],
   "source": [
    "!pip install \"datasets\" \"torch\" \"torchvision\" \"torchaudio\" \"transformers\" \"accelerate\" \"trl\" --quiet\n",
    "!pip install bitsandbytes --quiet\n",
    "!pip install huggingface_hub --quiet\n",
    "!pip install flash-attn --no-build-isolation --quiet\n",
    "!pip install peft --quiet\n",
    "!pip install tf-keras --quiet\n",
    "!pip install opacus --quiet\n",
    "!pip install flwr --quiet\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199c2082-329f-4643-844d-80b5cbe3389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 04:41:00.149730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739853660.159948  531613 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739853660.163083  531613 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 04:41:00.174409: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainerCallback, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, LoraModel\n",
    "from trl import SFTTrainer, setup_chat_format, SFTConfig\n",
    "from opacus import PrivacyEngine, GradSampleModule\n",
    "from datasets import Dataset, load_dataset\n",
    "from accelerate import Accelerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9ddf3c-4e33-4b90-b1a0-99b35963f4db",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JSON 데이터 로드 함수\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    formatted_data = []\n",
    "    for item in dataset[\"instances\"]:\n",
    "        formatted_data.append({\n",
    "            \"input_text\": item[\"input_text\"],\n",
    "            \"response_text\": item[\"response_text\"]\n",
    "        })\n",
    "    return formatted_data\n",
    "\n",
    "def format_instruction(dataset):\n",
    "    # 포맷팅된 데이터 생성\n",
    "    # Definition 부분\n",
    "    definition = 'Print a list of prescription drug names and drug routes that are appropriate for the icd diagnosis history using the patients personal information and diagnosis. Example: 39-year-old Female patient, Blood Pressure: 120/70, Height(cm): 160.0, Weight(kg): 77.6, ICD Diagnosis history : [Diverticulitis of colon (without mention of hemorrhage), Abscess of intestine, Depressive disorder, not elsewhere classified], it should be output as follows: Prescription drug (ex:drug-route) : [Morphine Sulfate - IV, Acetaminophen - PO, HYDROmorphone (Dilaudid) - IV, Morphine Sulfate - IV, Oxycodone-Acetaminophen - PO, 5% Dextrose - IV, Ciprofloxacin IV - IV, Potassium Chl 20 mEq / 1000 mL D5 1/2 NS - IV, SW - IV, Magnesium Sulfate - IV, NS - IV, MetRONIDAZOLE (FLagyl) - IV, NS (Mini Bag Plus) - IV, Ampicillin Sodium - IV, Codeine Sulfate - PO, Ondansetron - IV, Ondansetron - IV, Sodium Chloride 0.9%  Flush - IV, Morphine Sulfate - IV, Bisacodyl - PR, Potassium Chl 20 mEq / 1000 mL D5 1/2 NS - IV, Morphine Sulfate - IV, Fluoxetine - PO, Heparin - SC]'\n",
    "    chat_input = [\n",
    "        {\"role\": \"system\", \"content\": definition},\n",
    "        {\"role\": \"user\", \"content\": dataset[\"input_text\"]},\n",
    "        {\"role\": \"assistant\", \"content\": dataset[\"responses_text\"]}\n",
    "    ]\n",
    "    formatted_sample = tokenizer.apply_chat_template(chat_input, tokenize=False, max_length = 2048)\n",
    "    return formatted_sample\n",
    "\n",
    "# 데이터셋 나누기\n",
    "dataset_path = \"/tf/notebooks/NFS_dataset/Federated_Inference/MIMIC_Hospital_train.json\"\n",
    "dataset = load_data(dataset_path)\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3385e35-cf0b-4160-951d-34a36bf96ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2636e52a7c144cdbf766a8e5246f673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/18/2025 04:41:10:WARNING:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"  # 사용할 모델 ID\n",
    "use_flash_attention = True  # Flash Attention 사용 여부 설정\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_cache=False,  # 캐시 사용 안 함, Flash_Attention을 사용하게 된다면 use_cache는 사용하지 못함, 따라서 use_cache는 추론시에만 사용\n",
    "        attn_implementation = \"flash_attention_2\", # use_flash_attention_2=use_flash_attention,  # FlashAttention 사용 여부\n",
    "        device_map='auto',\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)  # 토크나이저 불러오기\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"  \n",
    "tokenizer.padding_side = \"right\"  # 패딩을 오른쪽에 추가\n",
    "\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93202aa6-5112-41a2-bbd5-32ba814c8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    init_lora_weights = 'gaussian', #  LoRA 레이어의 초기 가중치를 Gaussian 분포에서 샘플링하여 초기화\n",
    "    r=16,  # LoRA 차원 수 8, 16, 32\n",
    "    lora_alpha=16,  # LoRA 스케일링 파라미터\n",
    "    lora_dropout=0.1,  # LoRA 드롭아웃 비율\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # LoRA를 적용할 모듈 / proj라고 붙은 이름들에 전부 붙일 수 있다.\n",
    "    bias=\"none\",  # 바이어스 처리 방법\n",
    "    task_type=\"CAUSAL_LM\"  # 작업 유형 (언어 모델링)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9940cf72-9184-4c64-852e-5c4e820d0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe7d7a7-e0fd-4840-98d3-a36192171f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    init_lora_weights = 'gaussian', #  LoRA 레이어의 초기 가중치를 Gaussian 분포에서 샘플링하여 초기화\n",
    "    r=16,  # LoRA 차원 수 8, 16, 32\n",
    "    lora_alpha=16,  # LoRA 스케일링 파라미터\n",
    "    lora_dropout=0.1,  # LoRA 드롭아웃 비율\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # LoRA를 적용할 모듈 / proj라고 붙은 이름들에 전부 붙일 수 있다.\n",
    "    bias=\"none\",  # 바이어스 처리 방법\n",
    "    task_type=\"CAUSAL_LM\"  # 작업 유형 (언어 모델링)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3 # 1e-4로 Loss감소율이 너무 낮아서 바꿈 (Loss 1.3 -> 1.28)\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=\"./checkpoint_single_Llama3_Data_final_500\", # 수정 필요할수도\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    save_strategy = \"steps\",\n",
    "    eval_strategy = \"steps\",\n",
    "    logging_steps = 20,\n",
    "    max_steps = 1000,\n",
    "    save_steps = 100,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    tf32=True,\n",
    "    max_seq_length=2048,\n",
    "    packing=True,\n",
    "    learning_rate = learning_rate,\n",
    "    warmup_ratio = 0.1\n",
    ")\n",
    "\n",
    "## BF16과 TF32를 동시에 설정하면?\n",
    "# 우선순위와 동작 방식\n",
    "# \t1.\tBF16 적용:\n",
    "# \t•\tbf16=True로 설정하면 **모델의 전체 데이터 유형(dtype)**이 torch.bfloat16으로 설정됩니다.\n",
    "# \t•\t모델의 파라미터와 연산이 기본적으로 BF16으로 처리됩니다.\n",
    "# \t2.\tTF32 적용:\n",
    "# \t•\ttf32=True는 GPU의 특정 연산(GEMM, 즉 행렬 곱셈 연산)에만 적용되며, BF16으로 설정된 연산에도 영향을 미칠 수 있습니다.\n",
    "# \t•\tBF16이 이미 설정된 경우에도, TF32는 행렬 곱셈 연산에서 사용될 수 있습니다.\n",
    "# 결론적으로, 모델의 파라미터가 BF16로 동작하면서, GPU의 행렬 곱셈 연산은 TF32 설정에 따라 최적화됩니다.\n",
    "\n",
    "# Flash Attention을 사용하는 경우 레이어 업캐스팅\n",
    "if use_flash_attention:\n",
    "    from deep_learning_pytorch_huggingface.training.utils.llama_patch import upcast_layer_for_flash_attention\n",
    "    torch_dtype = torch.bfloat16 if args.bf16 else torch.float16 if args.fp16 else torch.float32  # 데이터 타입 설정\n",
    "    model = upcast_layer_for_flash_attention(model, torch_dtype)  # Flash Attention을 위한 업캐스팅 적용\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# FA-LoRA 설정\n",
    "# lora_A 파라미터 동결, 나머지 파라미터는 미세 조정 허용\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora_A' in name:  # lora_A 파라미터인 경우\n",
    "        param.requires_grad = False  # 이 파라미터 동결\n",
    "\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "335c2476-e711-4369-abd9-6361cf95b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/12/2025 06:42:06:WARNING:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  # 모델\n",
    "    train_dataset=train_data,  # 훈련 데이터셋\n",
    "    eval_dataset=val_data,  # 검증 데이터셋 추가\n",
    "    peft_config=peft_config,  # LoRA 설정\n",
    "    tokenizer=tokenizer,  # 토크나이저\n",
    "    formatting_func = format_instruction,\n",
    "    args=args,  # 훈련 인자\n",
    "    optimizers = (optimizer, None) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321002a7-5868-41fd-91cb-e429ce0aa30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='241' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 241/1000 7:26:32 < 23:38:04, 0.01 it/s, Epoch 0.28/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.124700</td>\n",
       "      <td>1.129022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.117700</td>\n",
       "      <td>1.118385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.105500</td>\n",
       "      <td>1.100603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.095600</td>\n",
       "      <td>1.079751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.070400</td>\n",
       "      <td>1.059093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.052300</td>\n",
       "      <td>1.040802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.033200</td>\n",
       "      <td>1.026863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.016300</td>\n",
       "      <td>1.015970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.010800</td>\n",
       "      <td>1.006696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.989800</td>\n",
       "      <td>0.992835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='1227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 620/1227 14:07 < 13:50, 0.73 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f7296-614e-40d0-a297-06fbf2da6c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95205d4-f9b6-4c63-ad2f-1cb5120d97f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246da19-e610-4274-85d5-578e59aa6069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f33a654-98f2-496d-877a-fb99fc3b2c57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.0.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.0.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.1.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.1.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.2.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.2.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.3.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.3.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.4.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.4.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.5.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.5.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.6.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.6.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.7.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.7.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.8.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.8.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.9.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.9.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.10.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.10.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.11.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.11.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.12.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.12.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.13.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.13.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.14.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.14.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.15.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.15.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.16.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.16.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.17.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.17.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.18.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.18.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.19.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.19.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.20.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.20.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.21.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.21.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.22.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.22.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.23.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.23.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.24.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.24.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.25.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.25.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.26.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.26.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.27.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.27.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.28.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.28.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.29.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.29.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.30.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.30.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.q_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.31.self_attn.k_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.v_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: Frozen\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: Trainable\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight: Frozen\n",
      "base_model.model.model.layers.31.input_layernorm.weight: Frozen\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight: Frozen\n",
      "base_model.model.model.norm.weight: Frozen\n",
      "base_model.model.lm_head.weight: Frozen\n"
     ]
    }
   ],
   "source": [
    "model.enable_input_require_grads()\n",
    "# 레이어 동결 상태 출력\n",
    "def print_layer_freeze_status(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        status = \"Frozen\" if not param.requires_grad else \"Trainable\"\n",
    "        print(f\"{name}: {status}\")\n",
    "\n",
    "# 동결 상태 확인\n",
    "print_layer_freeze_status(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
